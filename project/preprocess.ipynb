{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eWVSoXffWQT8"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import torch\n",
        "\n",
        "# Importing libraries\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset\n",
        "from typing import Tuple, List\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from nltk.corpus import words, wordnet\n",
        "import nltk\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVBKIRZjWQT9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9EtYzHYWQT-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_PATH = 'drive/MyDrive/NLP_project/'\n",
        "# BASE_PATH = './'\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    raise ValueError('path does not exist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-gs8NFdWQT-"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def skip(line, cell):\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOqCLTAtWQT_"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjrlslx0WQUA"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zda24XInWQUB"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(BASE_PATH + 'datasets/EmoTrain.csv')\n",
        "df_test = pd.read_csv(BASE_PATH + 'datasets/EmoVal.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMQhFoJIWQUC"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.drop(axis=1, columns=['Unnamed: 0'])\n",
        "df_test = df_test.drop(axis=1, columns=['Unnamed: 0'])\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step = 5_000\n",
        "df_train = df_train[:190_000]\n",
        "df_test = df_test[:190_000]\n",
        "# df_train = df_train[:100_000]\n",
        "# df_test = df_test[:100_000]"
      ],
      "metadata": {
        "id": "6oNbaakAYQXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agWcsylMWQUD"
      },
      "source": [
        "# Pre processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQdkqUIfWQUE"
      },
      "source": [
        "## Description of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNngpiRyWQUE"
      },
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSKIhk4fWQUF"
      },
      "outputs": [],
      "source": [
        "print(df_train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM9Kb2IzWQUF"
      },
      "outputs": [],
      "source": [
        "def split_features_labels(df) -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    x = df['text']\n",
        "    y = df.drop(axis=1, columns=['text'])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "x_train, y_train = split_features_labels(df_train)\n",
        "x_test, y_test = split_features_labels(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIGBhLtpWQUF"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHcfet2HWQUG"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKxCTm3qWQUG"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIwps6cPWQUG"
      },
      "source": [
        "Lower case all the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Mae5oDSWQUG"
      },
      "outputs": [],
      "source": [
        "def lower_case(x):\n",
        "    x = x.str.lower()\n",
        "    return x\n",
        "\n",
        "x_train = lower_case(x_train)\n",
        "x_test = lower_case(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO1L4COwWQUH"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZVZdk_QWQUH"
      },
      "source": [
        "Convert to tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDFOoP1MWQUH"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.to_list()\n",
        "x_test = x_test.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y74a6R5TWQUH"
      },
      "outputs": [],
      "source": [
        "print(len(x_train))\n",
        "print(x_train[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-o-3Y1pWQUI"
      },
      "outputs": [],
      "source": [
        "def list_of_words(x):\n",
        "    x = list(map(lambda i: i.split(), x))\n",
        "    return x\n",
        "\n",
        "x_train = list_of_words(x_train)\n",
        "x_test = list_of_words(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6jLYC9tWQUI"
      },
      "source": [
        "Then we have **list** of **list** of **tokens**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyejy0KpWQUI"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhFJYYcWWQUI"
      },
      "source": [
        "What kind of **characters** are there in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoMSr-z4WQUI"
      },
      "outputs": [],
      "source": [
        "characters = {'isalnum': 0}\n",
        "for text in x_train:\n",
        "    for word in text:\n",
        "        for c in word:\n",
        "            if c.isalnum():\n",
        "                characters['isalnum'] += 1\n",
        "            elif c in characters:\n",
        "                characters[c] += 1\n",
        "            else:\n",
        "                characters[c] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYapNMbQWQUJ"
      },
      "outputs": [],
      "source": [
        "print(len(characters))\n",
        "keys = list(characters.keys())\n",
        "keys.sort()\n",
        "print(keys)\n",
        "characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzOv1jyRWQUJ"
      },
      "source": [
        "- Remove non-semantic characters\n",
        "- Convert `?` and `!` and `emojis` to tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhDEBCSxWQUJ"
      },
      "outputs": [],
      "source": [
        "def split_special_chars(word: str):\n",
        "    if word.isalnum():\n",
        "        return word, []\n",
        "    specials = list(filter(lambda c: c == '!' or c == '?', word))\n",
        "    return ''.join(filter(lambda c: c.isalnum(), word)), specials\n",
        "\n",
        "def clean_tokens(x):\n",
        "    for text in tqdm(x):\n",
        "        specials = []\n",
        "        for i, word in enumerate(text):\n",
        "            text[i], special_word = split_special_chars(word)\n",
        "            specials.extend(special_word)\n",
        "        text.extend(specials)\n",
        "\n",
        "clean_tokens(x_train)\n",
        "clean_tokens(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34x2QI7BWQUJ"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5zUMGskWQUJ"
      },
      "source": [
        "Remove stop-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujiQsZ9KWQUK"
      },
      "outputs": [],
      "source": [
        "print(len(ENGLISH_STOP_WORDS))\n",
        "print(ENGLISH_STOP_WORDS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(x):\n",
        "    x = list(map(lambda text: list(filter(lambda word: word not in ENGLISH_STOP_WORDS, text)), x))\n",
        "    return x\n",
        "\n",
        "x_train = remove_stop_words(x_train)\n",
        "x_test = remove_stop_words(x_test)"
      ],
      "metadata": {
        "id": "w_LBOWNlPUhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSUTbzbHWQUK"
      },
      "source": [
        "# Vectorize the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqMz0F9nWQUK"
      },
      "source": [
        "An example of vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUUfubckWQUL"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dtype=bool)\n",
        "for i, text in enumerate(tqdm(x_train[:5])):\n",
        "    for word in text:\n",
        "        df.loc[i, word] = True\n",
        "df.fillna(False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSeZnMPdWQUL"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = {}\n",
        "for text in x_train:\n",
        "    for word in text:\n",
        "            if word in top_words:\n",
        "                top_words[word] += 1\n",
        "            else:\n",
        "                top_words[word] = 1\n",
        "\n",
        "top_words_ordered = sorted(top_words.items(), key=lambda kv: kv[1])\n",
        "print(top_words_ordered)"
      ],
      "metadata": {
        "id": "WGKZdS5tQMz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(map(lambda x: x[1], top_words_ordered)).index(1))\n",
        "print(list(map(lambda x: x[1], top_words_ordered)).index(2))\n",
        "print(list(map(lambda x: x[1], top_words_ordered)).index(3))\n",
        "print(list(map(lambda x: x[1], top_words_ordered)).index(4))\n",
        "print(list(map(lambda x: x[1], top_words_ordered)).index(5))"
      ],
      "metadata": {
        "id": "bC6mLAQYSVuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = list(map(lambda x: x[0], top_words_ordered[-1000:]))\n",
        "print(len(word_list))"
      ],
      "metadata": {
        "id": "NMnqE3DyXRD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t7m6bKOWQUP"
      },
      "source": [
        "Create an index for every unique word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIj9AcCYWQUP"
      },
      "outputs": [],
      "source": [
        "tensor_index = {}\n",
        "for i, word in enumerate(tqdm(word_list)):\n",
        "    tensor_index[word] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkwRoVqBRrTj"
      },
      "outputs": [],
      "source": [
        "print(len(tensor_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check synonyms"
      ],
      "metadata": {
        "id": "t8HWA1hBqzS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')  # Download WordNet if not already installed\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for synset in wordnet.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name().lower())\n",
        "    return synonyms - {word}\n",
        "\n",
        "word = \"happy\"\n",
        "print(get_synonyms(word))"
      ],
      "metadata": {
        "id": "Sc6CVcihq1sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPNOzCdTWQUQ"
      },
      "source": [
        "Create a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wseVLA4YWQUQ"
      },
      "outputs": [],
      "source": [
        "def create_x_tensor(x, syn=False):\n",
        "    x_tensor = torch.zeros(len(x), len(tensor_index), dtype=torch.float16)\n",
        "    for i, text in enumerate(tqdm(x)):\n",
        "        for word in text:\n",
        "            if word in tensor_index:\n",
        "                x_tensor[i, tensor_index[word]] += 1\n",
        "                if syn:\n",
        "                    for syn_word in get_synonyms(word):\n",
        "                        if syn_word in tensor_index:\n",
        "                            x_tensor[i, tensor_index[syn_word]] += 1\n",
        "    return x_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr3mETmF4Q3z"
      },
      "outputs": [],
      "source": [
        "# x_train\n",
        "# last_index = 0\n",
        "# for i in range(0, len(x_train), step):\n",
        "#     last_index = i\n",
        "#     torch.save(create_x_tensor(x_train[i:i+step]), BASE_PATH + f'tensors/x_train_tensor{i//step}.pt')\n",
        "# torch.save(create_x_tensor(x_train[last_index:]), BASE_PATH + f'tensors/x_train_tensor{last_index//step + 1}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6s3W5lD4TVK"
      },
      "outputs": [],
      "source": [
        "torch.save(create_x_tensor(x_train, syn=True), BASE_PATH + 'tensors/x_train_tensor.pt')\n",
        "torch.save(create_x_tensor(x_test), BASE_PATH + 'tensors/x_test_tensor.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RtX7y4sWQUR"
      },
      "source": [
        "Convert labels to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcvv0SUpWQUR"
      },
      "outputs": [],
      "source": [
        "y_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzrHkHkjWQUR"
      },
      "outputs": [],
      "source": [
        "def create_y_tensor(y):\n",
        "    y_tensor = torch.tensor(y.values, dtype=torch.float16)\n",
        "    return y_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXD-3l176vx7"
      },
      "outputs": [],
      "source": [
        "# y_train\n",
        "# last_index = 0\n",
        "# for i in range(0, len(y_train), step):\n",
        "#     last_index = i\n",
        "#     torch.save(create_y_tensor(y_train[i:i+step]), BASE_PATH + f'tensors/y_train_tensor{i//step}.pt')\n",
        "# torch.save(create_y_tensor(y_train[last_index:]), BASE_PATH + f'tensors/y_train_tensor{last_index//step + 1}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78D40DKvWQUR"
      },
      "outputs": [],
      "source": [
        "torch.save(create_y_tensor(y_train), BASE_PATH + 'tensors/y_train_tensor.pt')\n",
        "torch.save(create_y_tensor(y_test), BASE_PATH + 'tensors/y_test_tensor.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}